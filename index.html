<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <title>AI Reading group</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="css/header.css">
    <link rel="stylesheet" href="css/timeline.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">


</head>

<body>
    <header>
        <a class="about">About</a>
        <img src="./docs/vaader-air.png" alt="air-logo" width="150">
        <h1 class="text-center">Vaader AI Reading Group</h1>
    </header>
    <ul class="timeline">
        <li class="timeline-item period">
            <div class="timeline-info"></div>
            <div class="timeline-marker"></div>
            <div class="timeline-content">
                <h2 class="timeline-title">2021</h2>
            </div>
        </li>
        <li class="timeline-item">
            <a href="./pages/desnos-01-07-21/page.html">
                <div class="timeline-info">
                    <span>jul. 1, 2021</span>
                </div>
                <div class="timeline-marker"></div>
                <div class="timeline-content">
                    <h3 class="timeline-title">Paper Digest: “Dynamic Neural Networks: A Survey”
                    </h3>
                    <h5 class="timeline-title">Karol Desnos</h5>
                    <ul class="tags">
                        <li>Deep Learning</li>
                    </ul>
                    <p>
                        Dynamic neural network is an emerging research topic in deep learning. Compared to static models
                        which have fixed computational graphs and parameters at the inference stage, dynamic networks
                        can
                        adapt their structures or parameters to different inputs, leading to notable advantages in terms
                        of accuracy, computational efficiency, adaptiveness, etc. In this survey, we comprehensively
                        review
                        this rapidly developing area by dividing dynamic networks into three main categories: 1)
                        instance-wise dynamic models that process each instance with data-dependent architectures or
                        parameters; 2) spatial-wise dynamic networks that conduct adaptive computation with respect to
                        different spatial locations of image data and 3) temporal-wise dynamic models that perform
                        adaptive inference along the temporal dimension for sequential data such as videos and texts.
                        The
                        important research problems of dynamic networks, e.g., architecture design, decision making
                        scheme,
                        optimization technique and applications, are reviewed systematically. Finally, we discuss the
                        open
                        problems in this field together with interesting future research directions
                    </p>
                </div>
            </a>
        </li>
        <li class="timeline-item">
            <a href="./pages/bayou-outtas-16-06-21/page.html">
                <div class="timeline-info">
                    <span>jun. 16, 2021</span>
                </div>
                <div class="timeline-marker"></div>
                <div class="timeline-content">
                    <h3 class="timeline-title">Supervised learning to approximate model observer in task-based measure
                        of
                        image quality
                    </h3>
                    <h5 class="timeline-title">Meriem Bayou-Outtas</h5>
                    <ul class="tags">
                        <li>Deep Learning</li>
                    </ul>
                    <p>
                        The ability of an observer to perform a specific task on images, produced by a given medical
                        imaging
                        systems, defines an objective measure of image quality.
                        If the observer is “numerical”, can deep learning methods “do the job”? What we found in the
                        literature? Some papers rise this issue and propose to approximate the Ideal Observer for
                        performing
                        tasks detection and localization.
                    </p>
                </div>
            </a>
        </li>
        <li class="timeline-item">
            <a href="./pages/dardaillon-05-06-21/page.html">
                <div class="timeline-info">
                    <span>jun. 5, 2021</span>
                </div>
                <div class="timeline-marker"></div>
                <div class="timeline-content">
                    <h3 class="timeline-title">A gentle introduction to hardware architectures for DNN acceleration
                    </h3>
                    <h5 class="timeline-title">Mickaël Dardaillon</h5>
                    <ul class="tags">
                        <li>Deep Learning</li>
                    </ul>
                    <p>
                        “The synergy between the large datasets in the cloud and the numerous computers that power it
                        has
                        enabled remarkable advancements in machine learning, especially in DNNs. […] That changed in
                        2013
                        when a projection in which Google users searched by voice for three minutes per day using speech
                        recognition DNNs would double Google datacenters’ computation demands.”

                        This presentation will introduce the concepts behind the hardware architectures used to support
                        current growth in machine learning, including GPUs and TPUs.
                    </p>
                </div>
            </a>
        </li>
        <li class="timeline-item">
            <a href="./pages/aouayeb-22-04-21/page.html">
                <div class="timeline-info">
                    <span>apr. 22, 2021</span>
                </div>
                <div class="timeline-marker"></div>
                <div class="timeline-content">
                    <h3 class="timeline-title">Travel in the Deep Learning
                    </h3>
                    <h5 class="timeline-title">Mouath Aouayeb</h5>
                    <ul class="tags">
                        <li>Deep Learning</li>
                    </ul>
                    <p>
                        Traveling at the time of coronavirus is difficult with the restrictions set by governments all
                        around the world and that’s why most international meetings and conferences are held online. On
                        the
                        other side, deep learning has grown significantly in the past few years and especially for
                        vision
                        applications. Different architectures and models from CNNs to Transformers have been proposed.
                        In
                        this talk, we will not present another model, but we will list different techniques, layers,
                        loss
                        functions, and optimizers that can improve the performance of your model. Also, an analogy
                        between
                        travel and deep learning is presented in the beginning.
                    </p>
                </div>
            </a>
        </li>
        <li class="timeline-item">
            <a href="./pages/honorat-04-04-21/page.html">
                <div class="timeline-info">
                    <span>apr. 4, 2021</span>
                </div>
                <div class="timeline-marker"></div>
                <div class="timeline-content">
                    <h3 class="timeline-title">Optimizing implementation of CNN inferences: change the model or the
                        architecture?
                    </h3>
                    <h5 class="timeline-title">Alexandre Honorat</h5>
                    <ul class="tags">
                        <li>CNN</li>
                    </ul>
                    <p>
                        CNN are now widely used so it is necessary to implement them efficiently. To do so, CNN are most
                        commonly implemented on GPU processors, and also a bit on FPGA. In this talk, without entering
                        into
                        the details, we will list some problems arising when implementing the CNN inferences, especially
                        on
                        FPGA. We will also link these problems to the CNN models themselves and we will highlight a few
                        general recommendations extracted from the following papers.
                    </p>
                </div>
            </a>
        </li>
        <li class="timeline-item">
            <a href="./pages/faye-18-04-21/page.html">
                <div class="timeline-info">
                    <span>mar. 18, 2021</span>
                </div>
                <div class="timeline-marker"></div>
                <div class="timeline-content">
                    <h3 class="timeline-title">Dense-Gated Blocks, towards layers relationships in densely connected
                        blocks
                    </h3>
                    <h5 class="timeline-title">Joseph Faye</h5>
                    <ul class="tags">
                        <li>CNN</li>
                    </ul>
                    <p>
                        ResNet, Highway networks to DenseNet, adding more inter-layer connections besides the
                        direct connection in adjacent layers, emerged as popular approaches to strengthen feature
                        propagation among different layers. However, dense connections cause much redundancy especially
                        in
                        the case of DenseNet. Another aspect is that for many dense connections from previous layers,
                        the
                        role played by the mainstream module is unclear. To address these issues, authors introduce a
                        gating
                        mechanism, inspired by SENeT to model the layer relationships in densely connected blocks.
                    </p>
                </div>
            </a>
        </li>
        <li class="timeline-item">
            <a href="./pages/marie-04-03-21/page.html">
                <div class="timeline-info">
                    <span>mar. 4, 2021</span>
                </div>
                <div class="timeline-marker"></div>
                <div class="timeline-content">
                    <h3 class="timeline-title">ConvNets and humans are not biased towards the same information in images
                    </h3>
                    <h5 class="timeline-title">Alban Marie</h5>
                    <ul class="tags">
                        <li>CNN</li>
                    </ul>
                    <p>
                        Nowadays, it is well established that ConvNets are able to achieve incredible performance on
                        complex
                        vision task such as classification, object recognition or semantic segmentation. A common
                        thought is
                        that humans and ConvNets are able to solve these tasks by learning increasingly complex
                        representations of object shapes. However, recent studies show that humans and ConvNets have
                        indeed
                        very different strategies by not being biased towards the same information in images. To this
                        end,
                        authors propose a stylized version of ImageNet , allowing ConvNets to learn images
                        representation
                        used by humans easier.
                    </p>
                </div>
            </a>
        </li>
        <li class="timeline-item">
            <a href="./pages/beuve-18-02-21/page.html">
                <div class="timeline-info">
                    <span>feb. 18, 2021</span>
                </div>
                <div class="timeline-marker"></div>
                <div class="timeline-content">
                    <h3 class="timeline-title">Image-to-image translation with GANs</h3>
                    <h5 class="timeline-title">Nicolas Beuve</h5>
                    <ul class="tags">
                        <li>GAN</li>
                    </ul>
                    <p>
                        Image-to-image translation is a realm aiming at transposing images from one representation to
                        another, like generating an aerial map of a region based on a photograph. Results in this field
                        were
                        greatly improved since the arrival of GAN models in 2014. GANs (Generative Adversarial Nets) are
                        neural networks, specialized in sample generation. When applied to an image, those models are
                        able
                        to generate convincing samples that are similar to images from a reference dataset while
                        remaining
                        completely original.
                    </p>
                </div>
            </a>
        </li>
        <li class="timeline-item">
            <a href="./pages/peyramaure-04-02-21/page.html">
                <div class="timeline-info">
                    <span>feb. 4, 2021</span>
                </div>
                <div class="timeline-marker"></div>
                <div class="timeline-content">
                    <h3 class="timeline-title">Maybe BERT is all you need ?</h3>
                    <h5 class="timeline-title">Paul Peyramaure</h5>
                    <ul class="tags">
                        <li>Transformer</li>
                        <li>Attention</li>
                        <li>NLP</li>
                    </ul>
                    <p>
                        BERT, which stands for Bidirectional Encoder Representations from Transformer, has been
                        published by
                        a Google AI team in 2018. It has been presented as a new cutting-edge model for Natural Language
                        Processing (NLP). Based on Transformer achitecture, it is design to learn bidirectional
                        representations by considering both the left and right contexts in all its layers.
                        While being initially introduced for NLP tasks, it has recently been used to model other tasks
                        such
                        as action recognition.
                    </p>
                </div>
            </a>
        </li>
        <li class="timeline-item">
            <a href="./pages/lemarchant-21-01-21/page.html">
                <div class="timeline-info">
                    <span>jan. 21, 2021</span>
                </div>
                <div class="timeline-marker"></div>
                <div class="timeline-content">
                    <h3 class="timeline-title">Transformers: Attention is all you need!</h3>
                    <h5 class="timeline-title">FLorian Lemarchant</h5>
                    <ul class="tags">
                        <li>Transformer</li>
                        <li>Attention</li>
                        <li>NLP</li>
                    </ul>
                    <p>
                        While the Transformer architecture has become the de-facto standard for natural language
                        processing tasks, its applications to computer vision remain limited. In vision,
                        attention is either applied in conjunction with convolutional networks, or used to
                        replace certain components of convolutional networks while keeping their overall
                        structure in place. It has been shown that this reliance on CNNs is not necessary and a
                        pure transformer applied directly to sequences of image patches can perform very well on
                        multiple image tasks.
                    </p>
                </div>
            </a>
        </li>
    </ul>


</body>

</html>

<!--
Copyright (c) 2017 by Brady Wright (http://codepen.io/phasethree/pen/NNOvrW)


Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-->